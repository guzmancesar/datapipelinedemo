Steps 


Requirements:
  - Homebrew ()
  - python (brew install python3)
  - pyspark (pip3 install python)
  - Java (brew install java)
  - AWS S3
  - Databricks

Steps 
1. Use pyspark to transform data before it hits storage (preprocessing)
2. create s3 bucket for data
3. assign permissions to an IAM user for the script to RWD s3 objects <- we are here
4. Demonstrate ETL capabilities (TBD)
5. Dashboarding (TBD)

